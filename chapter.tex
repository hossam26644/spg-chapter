%%%%%%%%%%%%%%%%%%% author.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample root file for your "contribution" to a contributed volume
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%% Springer %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% RECOMMENDED %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[graybox]{svmult}

% choose options for [] as required from the list
% in the Reference Guide

\usepackage{mathptmx}       % selects Times Roman as basic font
\usepackage{helvet}         % selects Helvetica as sans-serif font
\usepackage{courier}        % selects Courier as typewriter font
%\usepackage{type1cm}        % activate if the above 3 fonts are
                            % not available on your system
%
\usepackage{makeidx}         % allows index generation
\usepackage{graphicx}        % standard LaTeX graphics tool
                             % when including figure files
\usepackage{multicol}        % used for the two-column index
\usepackage[bottom]{footmisc}% places footnotes at page bottom

% see the list of further useful packages
% in the Reference Guide

\makeindex             % used for the subject index
                       % please use the style svind.ist with
                       % your makeindex program

%%%%%%%%%%%%%%%%%%%%
% Extra packages
%%%%%%%%%%%%%%%%%%%%
\usepackage{subfig}
\usepackage{minted}
\usepackage[numbers]{natbib}
\usepackage{setspace}
\bibliographystyle{unsrtnat}

\newminted{python}{fontsize=\footnotesize}

%%%%%%%%%%%%%%%%%%%%
% local macros
%%%%%%%%%%%%%%%%%%%%

\newcommand{\msprime}[0]{\texttt{msprime}}
\newcommand{\ms}[0]{\texttt{ms}}
\newcommand{\apiref}[1]{\texttt{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title*{Coalescent simulation with msprime}
\titlerunning{Coalescent simulation with msprime}
\author{Jerome Kelleher and Konrad Lohse}
\institute{Jerome Kelleher \at
Big Data Institute, Li Ka Shing Centre for Health Information and Discovery,
University of Oxford, Oxford, OX3 7FZ, UK. \email{jerome.kelleher@bdi.ox.ac.uk}
\and Konrad Lohse \at Institute of Evolutionary Biology, University of Edinburgh,
King's Buildings, Edinburgh EH9 3FL, UK. \email{konrad.lohse@ed.ac.uk}}
%
% Use the package "url.sty" to avoid
% problems with special characters
% used in your e-mail or web address
%
\maketitle
\tableofcontents
\newpage
\doublespacing



\abstract{
Coalescent simulation is a fundamental tool in modern population genetics.
The \msprime\ library provides
unprecedented scalablity in terms of both the simulations
that can be performed
as well as the efficiency with which the results can be processed. We show
how coalescent models for population structure and demography can be
constructed using a simple Python API, as well as how we can process
the results of such simulations to efficiently calculate statistics of
interest. We illustrate \msprime's flexibility by implementing
a simple (but functional) approximate Bayesian computation inference method in
just a few tens of lines of code.\\
\textbf{Key words} Population genetics, coalescent theory, simulation, Python}

\section{Introduction}
\label{sec:introduction}

Thanks to the rapid advances in sequencing technology, generating
genome-wide sequence datasets for many species has become routine and
there is great interest in learning about the history of
populations from sequence variation. The
coalescent~\citep{hudson1983testing,kingman1982coalescent,Tajima1983Evolutionary}
gives an
elegant mathematical description of the ancestry of a sample of
sequences from a more or less idealized population and, given its focus
on samples, has become the backbone of modern population
genetics~\citep{hudson1990gene,wakely2008coalescent}.
However, despite the flood of sequence data and the plethora of
coalescent-based inference tools now available, many analyses of genome
wide variation remain superficial or entirely descriptive. Progress on
developing efficient inference methods has been hindered in two ways.
First, analytic results for models of population structure and/or history are
often restricted to average coalescence times and small (often pairwise)
samples. Even when it is possible to derive the full distribution of
genealogies for realistic models and samples sizes, the results are
cumbersome and generally rely on automation using symbolic mathematics software~\citep{Lohse2016}. Second, and
perhaps more fundamentally, dealing with recombination has proven
extremely challenging and we still lack analytic results for basic population genetic quantities for a linear sequence with recombination even under the simplest null models of
genetic drift. Thus, inference methods that
incorporate linkage information~\citep{li2011inference,harris2013inferring} generally rely on substantial simplifying
assumptions about recombination~\citep{mcvean2005approximating}.

Because analytic approaches relating sequence variation to mechanistic models
of population structure and history are severely limited, simulations---in particular, coalescent
simulations---have become an integral part of inference in a number of ways.
First, comparisons between analytic results and simulations serve as an important
sanity check for both. Second, while it is often possible to use analytic
approaches to obtain unbiased point estimates of demographic parameters by
ignoring linkage~\citep{gutenkunst2009inferring}, quantifying the uncertainty
and potential biases in such estimates requires parametric bootstrapping on
data simulated with linkage. Finally, a range of inference methods directly rely on
coalescent simulations to approximate the likelihood (or in a Bayesian setting,
the posterior) of parameters under arbitrarily complex models of demography.
Inference based on approximate Bayesian computation (ABC)~\citep{Beaumont2002,
Cornuet2008} or approximate likelihoods can be based either on single nucleotide polymorphisms (SNPs)
~\citep{excoffier2013} or multilocus data~\citep{becquet2007new, Beeravolu2017}.

This chapter is a tutorial for running and analysing coalescent simulations
using \msprime~\citep{kelleher2016efficient}.
As the name implies, \msprime\ is heavily indebted to the classical
\ms\ program~\citep{hudson2002generating}, and largely follows the
simulation model that it popularised. The methods for representing
genealogies that underlie \msprime\ are based on earlier work on simulating coalescent
processes in a spatial
continuum~\citep{kelleher2013coalescent,kelleher2014coalescent}.
There are many other coalescent simulators available---see~\citep{carvajal2008simulation,liu2008survey,arenas2012simulation,
yuan2012overview,hoban2012computer} for reviews---but \msprime\ has
some distinct advantages. Firstly, \msprime\ is capable of simulating
sample sizes far larger than any other simulator, and is generally
extremely efficient. The ability to simulate
hundreds of thousands of realistic human genomes has already enabled simulation studies that were hitherto impossible~\citep{martin2017human}.
Secondly, \msprime\ can simulate realistic models of recombination over
whole chromosomes without resorting to approximations. The
Sequentially Markov Coalescent (SMC)
approximation~\citep{mcvean2005approximating} was largely motivated by the
need to efficiently simulate chromosome-length sequences under the effects of
recombination,
which was unfeasible with simulators such as \ms~\citep{hudson2002generating}.
However, for large sample sizes, \msprime\ is significantly
faster than the most efficient SMC simulator~\citep{staab2014scrm},
rendering this approximation unnecessary for simulation
purposes~\citep{kelleher2016efficient}.
(The SMC is an important analytic approximation, however, and has lead to many important advances in inference; see e.g.~\citep{
li2011inference,
harris2013inferring,
schiffels2014inferring,
rasmussen2014genome}. See also Chapter 1 in this volume for formal definitions
of the SMC approximation, and Chapters 7, 8 and 10 for further applications.)
Thirdly, the data structure that \msprime\ uses
to represent the results of simulations is extremely concise and
can be efficiently processed. This data structure is known as a
\emph{succinct tree sequence} (or tree sequence for brevity),
and its applications to other areas
of population genomics is an active research
topic~\citep{kelleher2018efficient}. The tree sequence data
structure reduces the amount of space
required to store simulations and removes the significant
overhead of loading and parsing large volumes of text in order to analyse
simulation data. As we see in Section~\ref{processing-results}, it also
leads to powerful algorithms for analysing variation data. Finally,
\msprime's primary interface is through a simple but powerful Python
API, providing many advantages over command-line or GUI based alternatives.
One of the advantages of this approach is the ease with which we
can integrate with state-of-the-art analysis tools from the Python
ecosystem such as NumPy~\citep{walt2011numpy}, SciPy~\citep{jones-2018-scipy},
Matplotlib~\citep{hunter2007matplotlib}, Pandas~\citep{mckinney2010data},
Seaborn~\citep{michael_waskom_2017_883859}, and
Jupyter Notebooks~\citep{perez2007ipython}. Part of the goal
of this tutorial is to provide idiomatic examples for interacting
with these toolkits.

We assume a minimal working knowledge of Python, although it should be
possible to follow and replicate the examples given here with no prior
knowledge. All of the examples
given here can be found in the accompanying Jupyter notebook (see
the Online Resources section at the end of this chapter for details.)
For those beginning with Python, we recommend the
tutorial that is part of the official documentation.
We also assume a basic knowledge of coalescent theory;
\cite{wakely2008coalescent} is an excellent introduction.

The chapter is organised as follows.
Section~\ref{running-simulations} provides an overview of how to run coalescent simulations in \msprime, including some of the most important extensions to the basic model.
Section~\ref{processing-results} illustrates by way of simple examples how we can efficiently process the results
of such simulations, with particular emphasis on the methods
required to work with large sample sizes. We then provide
some examples of how to compare simulations with analytic
predictions in Section~\ref{validating-analytical-predictions},
emphasising idiomatic ways of interacting with toolkits such as
Pandas and Seaborn. In Section~\ref{sec:inference}, we show
how \msprime\ can be used to set up a simple ABC inference.
Inference tools are generally implemented with a command line or graphical
user interface and designed for a more or less narrow set of inference
problems. Thus the aim of Section~\ref{sec:inference} is to illustrate how
\msprime's flexible Python API can be used to build inference tools for arbitrary demographic histories from first principle.
Finally, we outline some future plans for \msprime\ in Section~\ref{sec:discussion}.

\section{Running simulations}
\label{running-simulations}
In the following subsections we examine some basic examples of running
simulations with \msprime, starting with the simplest possible models
and adding the various complexities required to model biological populations.
We use a notebook-like approach throughout, where we
intersperse code chunks and their results freely within the text.

\subsection{Trees and replication}
At the simplest level, coalescent simulation is about generating trees (or genealogies).
These trees (which are always rooted) represent the simulated history of a sample of individuals
drawn from an idealised population (in later sections we show how to
vary the properties of this idealised population). The function
\texttt{msprime.simulate} runs these simulations and the parameters
that we provide define the simulation that is
run. It returns a \texttt{TreeSequence} object, which represents the
full coalescent history of the sample. In later sections we discuss the
effects of recombination, when this \texttt{TreeSequence} contains a
sequence of correlated trees. For now, we focus on non-recombining sequences and
use the method \texttt{first()} to obtain the
tree object from this tree sequence. (In general, we can use the \texttt{trees()} iterator
to get all trees; see Section~\ref{recombination}.) For example, here we simulate a
history for a sample of three chromosomes:

\begin{figure}[t]
\begin{center}
\includegraphics[width=0.4\textwidth]{images/plot_1.pdf}
\end{center}
\caption{\label{fig-simple-tree} Coalescent tree with mutations.
using the \texttt{tree.draw()} method.}
\end{figure}

\begin{pythoncode}
import msprime
ts = msprime.sim_ancestry(3, ploidy=1)
tree = ts.first()
SVG(tree.draw())
\end{pythoncode}

This code chunk illustrates the basic approach required to draw a tree
in a Jupyter notebook. We first generate a tree sequence object (\texttt{ts}),
and we then obtain the tree object representing the first (and only)
tree in this sequence. Finally, we draw a representation of this tree
using the IPython SVG function on the output of the \texttt{tree.draw()}
method. By default, \texttt{tree.draw()} returns a depiction of the tree
in SVG format, but also supports plain text rendering. For example,
\texttt{print(tree.draw(format="unicode"))} prints the tree to the console
using Unicode box-drawing characters. This is a very useful debugging tool.
We have omitted the \texttt{import} statements required for the \texttt{SVG}
function here as it is rather specific to the Jupyter notebook environment.
All code chunks in this chapter are included in the accompanying Jupyter
notebook and are fully runnable.

The output of one random realisation of this process is shown in
Figure~\ref{fig-simple-tree}. The resulting tree has 5 nodes: nodes 0, 1 and 2 are \emph{leaves}, and
represent our samples. Node 3 is an \emph{internal} node, and is the
parent of 0 and 1. Node 4 is also an internal node, and is the root of
the tree. In \msprime, we always refer to nodes by their integer IDs and
obtain information about these nodes by calling methods on the tree
object. For example the code \texttt{tree.children(4)} will return the
tuple \texttt{(1,\ 3)} here, as these are the node IDs of the children
of the root node. Similarly, \texttt{tree.parent(0)} will return
\texttt{3}.

The height of a tree node is determined by the \emph{time} at which the corresponding
ancestor was born. So,
contemporary samples always have a node time of zero, and time values
increase as we go upwards in the tree (i.e.\ further back in time). Times
in \msprime\ are always measured in \emph{generations}.

When we run a single simulation, the resulting tree is a single random
sample drawn from the probability distribution of coalescent trees. Since a
single random draw from any distribution is usually uninformative, we
nearly always need to run many different \emph{replicate} simulations to
obtain useful information. This simplest way to do this in \msprime\ is to
use the \texttt{num\_replicates} argument.

\begin{pythoncode}
import msprime
N = 1000
mean_T_mrca = 0
for ts in msprime.sim_ancestry(10, num_replicates=N, ploidy=1):
    tree = ts.first()
    mean_T_mrca += tree.time(tree.root)
mean_T_mrca = mean_T_mrca / N
print(mean_T_mrca)

>>> 1.7591899369100823
\end{pythoncode}

    In this example we run 1000 independent replicates of the coalescent for
a sample of 10 chromosomes, and compute the mean time to the MRCA of the entire sample, i.e., the root of the
tree. The value of 3.7 generations in the past we obtain is of course highly unrealistic.
However, by default, time is measured in units of \(4 N_e\) generations (see the next section for details on how to
specify population models and interpret times). It is important to note here
that although time is measured in units of generations, this is of course
an approximation and we may have fractional values. Internally,
during a simulation time is scaled into coalescent units
using the \texttt{Ne} parameter and once the
simulation is complete, times are scaled back into units of generations
before being presented to the user. This removes the burden of such
tedious time scaling calculations from the user. We discuss these time
scaling issues in more detail in the next section.

The
\texttt{simulate} function behaves slightly differently when it is
called with the \texttt{num\_replicates} argument: rather than returning
a single tree sequence, we return an \emph{iterator} over the individual
replicates. This means that we can use the
convenient \textbf{for} loop construction to consider each simulation in
turn, but without actually storing all these simulations. As a result,
we can run millions of replicates using this method without
using any extra storage.

When simulating coalescent trees, we are often interested in more than
just the mean of the distribution of some statistic. Rather than compute
the various summaries by hand (as we have done for the mean in the last
example), it is convenient to store the result for each
replicate in a NumPy array and analyse the data after the simulations have completed.
For example:

\begin{pythoncode}
import msprime
import numpy as np
N = 1000
T_mrca = np.zeros(N)
for j, ts in enumerate(msprime.sim_ancestry(10, num_replicates=N, ploidy=1)):
    tree = ts.first()
    T_mrca[j] = tree.time(tree.root)
print([np.mean(T_mrca), np.var(T_mrca)])

>>> (np.float64(1.855267280486074), np.float64(1.28673089924668))
\end{pythoncode}

    Here we simulate 1000 replicates, storing the time to the MRCA for each replicate in the array \texttt{T\_mrca}.  We use the Python \texttt{enumerate} function to simplify the process of efficiently inserting values into this
array, which simply ensures that \texttt{j} is \texttt{0} for the first replicate,
\texttt{1} for the second, and so on. Thus, by the time we finish the
loop, the array has been filled with $T_{MRCA}$ values generated
under the coalescent. We then use the NumPy library (which has
an extensive suite of statistical functions) to compute the mean and
variance of this array. This example is idiomatic, and we will use this
type of approach throughout. In the interest of brevity, we will omit all
further \texttt{import} statements from code chunks.

It is usually more convenient to use the \texttt{num\_replicates}
argument to perform replication, but there are situations in which it is
desirable to specify random seeds manually. For example, if simulations
require a long time to run, we may wish to use multiple processes to
run these simulations. To ensure that the seeds used in these different
processes are unique, it is best to manually specify them. For example,

\begin{pythoncode}
import concurrent.futures as cf

def run_simulation(seed):
    ts = msprime.sim_ancestry(10, random_seed=seed, ploidy=1)
    tree = ts.first()
    return tree.time(tree.root)

N = 1000
seeds = np.random.randint(1, 2**32 - 1, N)
with cf.ProcessPoolExecutor(max_workers=4) as executor:
     futures = [executor.submit(run_simulation, seed) for seed in seeds]
     T_mrca = np.array([f.result() for f in cf.as_completed(futures)])
print(np.mean(T_mrca))

>>> np.float64(1.7920618730043976)
\end{pythoncode}

    In this example we create a list of 1000 seeds between 1 and $2^{32} -
1$ (the range accepted by \msprime) randomly. We then use the
concurrent.futures module to create a process pool of four workers, and
run our different replicates in parallel. The results are then
collected together in an numpy array so that we can easily process them.
This approach is a straightforward way to utilise modern
multi-core processors.

Specifying the same random seed for two different simulations (with the
same parameters) ensures that we get precisely the same results from
both simulations (at least, on the same computer and with the same
software versions). This is very useful when we wish to examine the
properties of a specific simulation (for example, when debugging), or if
we wish to illustrate a particular example. We will often set the random
seed in the examples in this tutorial for this reason.

\subsection{Mutations}\label{mutations}

We cannot directly observe gene genealogies; rather, we observe mutations in a sample of sequences which ultimately have occurred on genealogical branches. We are
therefore very often interested not just in the genealogies generated by the coalescent process, but also in the results of
mutational processes imposed on these trees. \msprime\ simulates mutations under the infinitely many sites model by default
(arbitrarily complex mutations are supported by the underlying data model, however). This is
accessed by the \texttt{mutation\_rate} parameter to the
\texttt{simulate} function. As usual, this rate is the per-generation
rate.

\begin{figure}[t]
\begin{center}
\includegraphics[width=0.4\textwidth]{images/plot_2.pdf}
\end{center}
\caption{\label{fig-tree-mutations} Coalescent tree with mutations}
\end{figure}

\begin{pythoncode}
ts = msprime.sim_ancestry(3, ploidy=1, random_seed=7)
#sequence_length=2 to get similar results, or change to non discrete genome
ts = msprime.sim_mutations(ts, rate=1, random_seed=7, discrete_genome=False)
tree = ts.first()
SVG(tree.draw())
\end{pythoncode}

The tree produced by this code chunk is shown in
Figure~\ref{fig-tree-mutations}. Here we have two mutations, shown by the red squares.
Mutations occur above a given node in the tree, and all samples beneath
this node will inherit the mutation. The infinite sites mutations used
here are simple binary mutations, that is, the ancestral state is 0 and
the derived state is 1. One convenient way to access the resulting
sample genotypes is to use the \texttt{genotype\_matrix()} method, which
returns an \(m \times n\) NumPy array, if we have \(m\) variable sites
and \(n\) samples. Thus, if \(G\) is the genotype matrix, \(G[j, k]\) is
the state of the \(k\)th sample at the \(j\)th site. In our example
above, the site 0 has a mutation over node 3, and site 1 has a mutation
over node 1, and so we get the following matrix:

\begin{pythoncode}
ts.genotype_matrix()
>>> array([[0, 1, 0],
           [1, 0, 1]], dtype=int32)
\end{pythoncode}

    The genotype matrix gives a convenient way of accessing genotype
information, but will consume a great deal of memory for larger
simulations. See Section~\ref{processing-variants} for more information
on how to access genotype data efficiently.

When comparing simulations to analytic results, it is very important to be aware of the way in which the
mutation rates are defined in coalescent theory. For historical reasons,
the scaled mutation rate \(\theta\) is defined as \(2N_e \mu\), where
\(\mu\) is the per-generation mutation rate. Since all times and rates
are specified in units of generations in \msprime, we must divide by a
factor of two if we are to compare with analytic predictions. For
example, the mean number of segregating sites for a sample of two is
\(\theta\); to run this in \msprime\ we do the following:

\begin{pythoncode}
N = 10000
theta = 5
S = np.zeros(N)
replicates = msprime.sim_ancestry(2, population_size=0.5, num_replicates=N, ploidy=1, discrete_genome=False)
for j, ts in enumerate(replicates):
    ts = msprime.sim_mutations(ts, rate=theta, discrete_genome=False)
    S[j] = ts.num_sites  # Number of segregrating sites.

print(np.mean(S))

>>> np.float64(5.0281)

\end{pythoncode}

    Note that here we set the mutation rate to \(\theta / 2\) (to cancel out
the factor of 2 in the definition of \(\theta\)) and \(N_e = 1/2\) (so
that time is measured in haploid coalescent time units). Such
factor-of-two gymnastics are unfortunately unavoidable in coalescent
theory.

\subsection{Demography}\label{Demography}

\subsubsection{Population size}\label{population-models}

In the previous section the only parameters we supplied to
\texttt{simulate} were the \texttt{sample\_size} and
\texttt{num\_replicates} parameters. This allows us to randomly sample
trees with a given number of nodes, but, as it leaves the population
unspecified, has little connection with
biological reality. The most fundamental population parameter is the \emph{effective population size}, or
\(N_e\). This parameter simply rescales time; larger effective
population sizes correspond to older coalescence times:

\begin{pythoncode}
def pairwise_T_mrca(population_size):
    N = 10000
    T_mrca = np.zeros(N)
    for j, ts in enumerate(msprime.sim_ancestry(2, population_size=population_size, num_replicates=N, ploidy=1)):
        tree = ts.first()
        T_mrca[j] = tree.time(tree.root)
    return np.mean(T_mrca)

print(
    pairwise_T_mrca(0.5), pairwise_T_mrca(10),
    pairwise_T_mrca(100))

>>> (np.float64(0.4955590279542856),
     np.float64(10.213697079990956),
     np.float64(101.4337058054171))

\end{pythoncode}

    Thus, when we specify \(N_e=10\) we get a mean pairwise coalescence time of about
20 generations, and with \(N_e=100\), the mean coalescence time is about
200 generations. See \cite{wakely2008coalescent} for details on the biological interpretation of effective population size.

By default, \(N_e = 1\) in \msprime, which is equivalent to measuring
time in units of \(N_e\) generations. It is very important to note that
\(N_e\) in \msprime\ is the \emph{diploid} effective population size,
which means that all times are scaled by \(2N_e\) (rather than $N_e$ for a
haploid coalescent). Thus, if we wish to compare the results that are
given in the literature for a haploid coalescent, then we must set
\(N_e\) to $1/2$ to compensate. For example, we know that the expected
coalescence time for a sample of size 2 is 1, and this is the value we
obtain from the \texttt{pairwise\_T\_mrca} function when we have
\(N_e=0.5\). We will usually assume that we are working in haploid
coalescent time units from here on, and so set \(N_e=0.5\) in most
examples. However, when running simulations of a specific organism and/or population, it
is substantially more convenient to use an appropriate estimated value
for \(N_e\) so that times are directly interpretable.

\runinhead{Exponentially growing/shrinking
populations}\label{exponentially-growingshrinking-populations} \

When we provide an \(N_e\) parameter, this specifies a fixed effective
population size. We can also model populations that are exponentially
growing or contracting at some rate over time. Given a population size
at the present \(s\) and a growth rate \(\alpha\), the size of the
population \(t\) generations in the past is $s e^{-\alpha t}$. (Note
again that time and rates are measured in units of \emph{generations},
not coalescent units.)

In \msprime, the initial size and growth rate for a particular population
are specified using the \texttt{PopulationConfiguration} object. A list
of these objects (describing the different populations; see
Section~\ref{population-structure}) are then provided to the
\texttt{simulate}
function. When providing a list of
\texttt{PopulationConfiguration\ objects}, the \texttt{Ne} parameter to
\texttt{simulate} is not required, as the \texttt{initial\_size} of the
population configurations performs the same task. For example,

\begin{pythoncode}
def pairwise_T_mrca(growth_rate):
    N = 10000
    T_mrca = np.zeros(N)
    demography = msprime.Demography.isolated_model(initial_size=[0.5],
                                                   growth_rate=[growth_rate])
    replicates = msprime.sim_ancestry(
        samples=2,
        demography=demography,
        num_replicates=N,
        ploidy=1,
        random_seed=100)

    for j, ts in enumerate(replicates):
        tree = ts.first()
        T_mrca[j] = tree.time(tree.root)
    return np.mean(T_mrca)

print(
    pairwise_T_mrca(0.05), pairwise_T_mrca(0),
    pairwise_T_mrca(-0.05))
>>> (np.float64(0.4775720920641944),
     np.float64(0.4889637700421355),
     np.float64(0.5015256860964078))
\end{pythoncode}

    Here we simulate the pairwise \(T_{MRCA}\) for positive, zero and
negative growth rates. When we have a growth rate of zero, we see that
recover the usual result of 1.0 (as our initial size, and hence \(N_e\),
is set to \(1/2\)). When the growth rate is positive, we see that the
mean coalescence time is reduced, since the population size is getting
smaller as we go backwards in time, resulting in an increased rate of
coalescence. Conversely, when we have a negative growth rate, the
population is getting larger as we go backwards in time, resulting in a
slower coalescence rate. (Care must be taken with negative growth rates,
however, as it is possible to specify models in which the MRCA is never
reached. In some cases this will lead to an error being raised, but it
is also possible that the simulator will keep generating events
indefinitely. This is particularly important in simulation based
approaches to inference from real data.)


\subsubsection{Population structure}\label{population-structure}

Following \ms~\citep{hudson2002generating}, \msprime\ supports a
discrete-deme model of population structure in which
\(d\) panmictic populations exchange migrants according to the rates
defined in an \(d \times d\) matrix. This approach is very flexible,
allowing us to simulate island models (in which all populations exchange
migrants at a fixed rate), one and two dimensional stepping stone models
(where migrants only move to adjacent demes) and other more complex
migration patterns. This population structure is declared in \msprime\ via the
\texttt{population\_configurations} and \texttt{migration\_matrix}
parameters in the \texttt{simulate} function. The list of population
configurations defines the populations; each element of this list must
be a \texttt{PopulationConfiguration} instance (each population has
independent initial population size and growth rate parameters). The
migration matrix is a NumPy array (or list of lists) of per-generation
migration rates; \(m[j,k]\) defines the fraction of population \(j\)
that consists of migrants from population \(k\) in each generation. (Note that when running simulations on the coalescence scale, i.e.\ setting \(N_e=1/2\), this is equivalent to the number of migrants per deme and generation \(M[j,k]=2 N_e m[j,k]\).)

\begin{pythoncode}
demography =  msprime.Demography.isolated_model([1, 1])
demography.set_migration_rate(source=0, dest=1, rate=0.1)

ts  = msprime.sim_ancestry(
    samples={0:2, 1:2}, ploidy=1,
    random_seed=2, demography=demography)
tree = ts.first()
colour_map = {0:"red", 1:"blue"}
node_colours = {u: colour_map[tree.population(u)] for u in tree.nodes()}
SVG(tree.draw(node_colours=node_colours))
\end{pythoncode}

We create our model by first making a list of two
\texttt{PopulationConfiguration} objects. For convenience here, we use
the \texttt{sample\_size} argument to these objects to state that we
wish to have two samples from each population. This results in samples
being allocated sequentially to the populations when \texttt{simulate}
is called: 0 and 1 are placed in population 0, and samples 2 and 3 are
placed in population 1. We then declare our migration matrix, which is
asymmetric in this example. Because ${M{[}0,1{]} = 0.1}$ and
${M{[}1, 0{]} = 0}$, forwards in time, individuals can migrate
from population 1 to population 0 but not vice-versa. This is illustrated in
Figure~\ref{fig-trees-migration-asymmetric} which shows the tree
produced by this simulation. Each node has been coloured by its
population (red is population 0 and blue population 1). Thus, the leaf
nodes 0 and 1 are both from population 0, and 2 and 3 are both from
population 2 (as explained above). As we go up the tree, the first event
that occurs is 2 and 3 coalescing in population 1, creating node 4.
After this, 4 coalesces with with node 0, which has at some point before
this migrated into deme 1, creating node 5. Node 1 also migrates into
deme 1, where it coalesces with 5. Because migration is asymmetric here,
the MRCA of the four samples \emph{must} occur
within deme 1.

\begin{figure}[t]
\centering
\subfloat[][Two populations with asymmetric migration]{
\includegraphics[width=0.3\textwidth]{images/plot_3.pdf}
\label{fig-trees-migration-asymmetric}}
\qquad\qquad
\subfloat[][Three population island model]{
\includegraphics[width=0.3\textwidth]{images/plot_4.pdf}
\label{fig-trees-island-model}}
\caption{\label{fig-trees-migration} Example trees produced in models with multiple
populations and migration. Nodes are coloured by population.}
\end{figure}

The exact history of migration events is available if we use the
\texttt{record\_migrations} option. In the next example, we set up a
symmetric island model and track every migration event:

\begin{pythoncode}
demography =  msprime.Demography.island_model([1, 1, 1], migration_rate=1)

ts  = msprime.sim_ancestry(
    samples={0:3, 1:1, 2:1},
    demography=demography,
    record_migrations=True,
    ploidy=1,
    random_seed=101)
tree = ts.first()
colour_map = {0:"red", 1:"blue", 2: "green"}
node_colours = {u: colour_map[tree.population(u)] for u in tree.nodes()}
SVG(tree.draw(node_colours=node_colours))
\end{pythoncode}

Figure~\ref{fig-trees-island-model} shows the tree produced by this code
chunk. Here we sample three nodes from population 0, but because there is a lot of migration, the locations of coalescences are quite random. For
example, the first coalescence occurs in deme 2 (green), after node 0
has migrated in. To see the details of these migration events, we can
examine the ``migration records'' that are stored by \msprime. (These are
not stored by default, as they may consume a substantial amount of memory.
The \texttt{record\_migrations} parameter must be
supplied to \texttt{simulate} to turn on this feature.) Migration
records store complete information about the time, source and
destination demes and the genomic interval in question. Here we are
interested in the total number of migration events experienced by each node:

\begin{pythoncode}
node_count = np.zeros(ts.num_nodes)
for migration in ts.migrations():
    node_count[migration.node] += 1
plt.bar(np.arange(ts.num_nodes), node_count)
plt.xlabel("Node ID")
plt.ylabel("Number of migrations");
\end{pythoncode}

\begin{figure}[t]
\begin{center}
\includegraphics[width=\textwidth]{images/plot_5.pdf}
\end{center}
\caption{\label{fig:migration_counts} Number of migration events for
each tree node in a simulation with migration.}
\end{figure}

This code produces the plot in Figure~\ref{fig:migration_counts}.
We can see that node 0 experienced very few migration events before it
ended up in deme 2, where it coalesced with 4 (which never migrated).
Node 2, on the other hand migrated 30 times before it finally coalesced
with 7 in deme 0. Note that there are many more migrations events than
nodes here, implying that most migration events are not identifiable
from a genealogy in real data~\citep{sousa2011nonidentifiability}.

Other forms of migration are also possible between specific demes at
specific times. These different demographic events are dealt with in the next section.

\subsubsection{Demographic events}\label{demographic-events}

Demographic events allow us to model more complex histories involving
changes to the population structure over time, and are specified using
the \texttt{demographic\_events} parameter to \texttt{simulate}. Each
demographic event occurs at a specific time, and the list of events must
be supplied in the order they occur (backwards in time). There are a
number of different types of demographic event, which we examine in
turn.

\runinhead{Migration rate change}\label{migration-rate-change}

Migration rate change events allow us to update the migration rate
matrix at some point in time. We can either update a single cell in the
matrix or all (non-diagonal) entries at the same time.
\begin{pythoncode}
demography = msprime.Demography.isolated_model([1, 1])

demography.add_migration_rate_change(time=20, rate=1, source=0, dest=1)
ts  = msprime.sim_ancestry(
    samples={0:2, 1:2},
    demography=demography,
    ploidy=1,
    random_seed=2)

tree = ts.first()

\end{pythoncode}

The tree produced by this code chunk is shown in
Figure~\ref{fig-trees-migration-rate-change} (in this example and those
following we have omitted the code required to draw the tree).
The samples 0 and 1, and 2 and 3 coalesce quickly within their
own populations. However, because the migration rate between the
populations is zero these lineages are isolated and would never coalesce
without some change in demography. The migration rate change event
happens at time 20, resulting in node 5 migrating to deme 1 soon
afterwards. The lineages then coalesce at time 21.4.

\begin{figure}[t]
\centering
\subfloat[][Migration rate change]{
\includegraphics[width=0.3\textwidth]{images/plot_6.pdf}
\label{fig-trees-migration-rate-change}}
% \qquad
\subfloat[][Mass migration]{
\includegraphics[width=0.3\textwidth]{images/plot_7.pdf}
\label{fig-trees-mass-migration}}
% \qquad
\subfloat[][Admixture]{
\includegraphics[width=0.3\textwidth]{images/plot_8.pdf}
\label{fig-trees-admixture}}
\caption{\label{fig-trees-demographic-events} Example trees produced in models
with demographic events. Nodes are coloured by population.}
\end{figure}


\runinhead{Mass migration}\label{mass-migration}

This class of event allows us to move some proportion of the lineages in
one deme to another at a particular time. This allows us to model
population splits and admixture events. Population splits occur
when (backwards in time) all the lineages in one population migrate to
another.

\begin{pythoncode}
demography = msprime.Demography.isolated_model([1, 1])
demography.add_mass_migration(time=15, source=1, dest=0, proportion=1)

ts  = msprime.sim_ancestry(
    samples={0:3, 1:3},
    demography=demography,
    ploidy=1,
    random_seed=20)
tree = ts.first()
\end{pythoncode}

The tree produced by this code chunk is shown in
Figure~\ref{fig-trees-mass-migration}. In this case we also have two isolated
populations which coalesce down to a single lineage. The population split at
time 15 (which, forwards in time produced all the individuals in population 1),
results in this lineage migrating back to population 0, where it coalesces with
the ancestor of the samples 0, 1 and 2.

Admixture events (i.e., where some fraction of the lineages move to a
different deme) are specified in the same way:

\clearpage
\begin{pythoncode}
demography = msprime.Demography.isolated_model([1, 1])

demography.add_mass_migration(time=0.5, source=0, dest=1, proportion=0.5)
demography.add_migration_rate_change(time=1.1, rate=0.1)

ts  = msprime.sim_ancestry(
    samples={0:6, 1:0},
    demography=demography,
    ploidy=1,
    random_seed=5)

tree = ts.first()
\end{pythoncode}

The tree produced by this code chunk is shown in
Figure~\ref{fig-trees-admixture}.
We begin in this example with 6 lineages sampled in population 0, zero
samples in population 1, and with no migration between these
populations. At time 0.5, we specify an admixture event where each of
the 4 extant lineages (5, 7, 0 and 6) has a probability of 1/2 of moving
to deme 1. Linages 0 and 6 migrate, and subsequently coalesce into node
8. Further back in time, at \(t=1.1\), another demographic event occurs,
changing the migration rate between the demes to 0.1, thereby allowing
lineages to move between them. Eventually, all lineages end up in deme
1, where they coalesce into the MRCA at time \(t=6.9\).

\runinhead{Population parameter change}\label{population-parameter-change}

This class of event represents a change in the growth rate or
size of a particular population. Since each population has its own
individual size and growth rates, we can change these arbitrarily as we
go backwards in time. Keeping track of the actual sizes of different
populations can be a little challenging, and for this reason \msprime\
provides a \texttt{DemographyDebugger} class.

To illustrate this, we consider a very simple example in which we have a
single population experiencing a phase of exponential growth from 750
to 100 generations ago. The size of the population 750 generations ago
was 2000, and it grew to 20,000 over the next 650 generations. The size
of the population has been stable at this value for the past 100
generations. We encode this model as follows:

\begin{pythoncode}
N1 = 20000  # Population size at present
N2 = 2000   # Population size at start (forwards in time) of exponential growth.
T1 = 100    # End of exponential growth period (forwards in time)
T2 = 750    # Start of exponential growth period (forwards in time)
# Calculate growth rate; solve N2 = N1 * exp(-alpha * (T2 - T1))
growth_rate = -np.log(N2 / N1) / (T2 - T1)
demography = msprime.Demography.isolated_model([N1])
demography.add_population_parameters_change(time=T1, growth_rate=growth_rate)
demography.add_population_parameters_change(time=T2, growth_rate=0)

dp = demography.debug()
dp.print_history()
\end{pythoncode}

Gives the output in figure~\ref{fig:DemographyDebugger}:

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{images/DemographyDebugger.pdf}
\caption{\label{fig:DemographyDebugger}A visualised \texttt{DemographyDebugger} output.}
\end{figure}

    After we set up our model, we use the \texttt{DemographyDebugger} to
check our calculations. We see that time has been split into three
``epochs''. From the present until 100 generations ago, the
population size is constant at 20,000. Then, we have a demographic event
that changes the growth rate to 0.0035, which applies over the next
epoch (from 100 to 750 generations ago). Over this time, the population
grows from 2000 to 20,000 (note that the ``start'' and
``end'' of each epoch is looking \emph{backwards} in time, as we consider
epochs starting from the present and moving backwards). At generation
750, another event occurs, setting the growth rate for the population to
0. Then, the population size is constant at 20,000 from generation 750
until the indefinite past.

A more complex example involving a three population out-of-Africa human
model is available in the online documentation.

\subsubsection{Using Demes standard format}\label{using-demes-standard-format}

The Demes format~\citep{gower_demes_2022} is a standard for writing
demographic models, to facilitate interchange between simulators, as well as between
demographic inference software and simulators. Demes models are typically written as a
YAML file, and loaded into Python using the demes library.

Consider the following Demes model that describes two extant demes A and B, which
have a common ancestor X.

\begin{footnotesize}
\begin{verbatim}
time_units: generations
defaults:
    {epoch: {start_size: 5000}}
demes:
    - {name: X, epochs: [{end_time: 1000}]}
    - {name: A, ancestors: [X]}
    - {name: B, ancestors: [X],
        epochs: [{end_time: 500, start_size: 2000},
        {end_time: 0, start_size: 400, end_size: 10000}]}
migrations:
    - {source: A, dest: B, rate: 1e-4}

\end{verbatim}
\end{footnotesize}

When visualised using \texttt{demesdraw}~\citep{gower_grahamgowerdemesdraw_2024},
the demographic model is represented as shown in Figure~\ref{fig-demes-plot}.
 In this plot, arrows indicate movement of individuals as time proceeds from
the past to the present.

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{images/demes.pdf}
\caption{\label{fig-demes-plot}A demes YAML file visualised using \texttt{demesdraw}.}
\end{figure}

To import demes from a YAML file, we can use the \texttt{demes.load()} function to
load a demes graph object. Then, the \texttt{Demography.from\_demes()} method is used to convert a
\texttt{demes graph} object into a \texttt{Demography} object. On the
other hand, the \texttt{Demography.to\_demes()} method performs the opposite conversion; it
converts a \texttt{Demography} object to a \texttt{demes graph} object, which can be then
exported as a YAML file.

For example:

\begin{pythoncode}
import demes
graph = demes.load("demes_example_01.yaml")
demography = msprime.Demography.from_demes(graph)
ts = msprime.sim_ancestry({"A":2, "B":3},
             demography=demography, random_seed=1234)
\end{pythoncode}

The previous code block loads the example demes model of figure~\ref{fig-demes-plot} from a YAML file. Then, a demography
object is created from the loaded deme graph. Finally, a tree is simulated using the demography object, with samples
drawn from demes A and B.


\subsubsection{Drawing samples}\label{ancient-samples}

The samples drawn from a simulation can be defined in one of three ways: by
simply providing an integer as the number of samples drawn from a single population,
by providing a dictionary with population names as keys and the number of
samples as values, or by providing a list of \texttt{SampleSet} objects.
An \msprime\ \texttt{SampleSet} object can be used to specify the sampling
time, the population, and the ploidy of a set of samples, making it the more
versatile option. However, in most cases, it is sufficient to define samples
using an integer or a dictionary.

Up to this point we have assumed that all samples are taken at the
present time. However, \msprime\ allows us to specify arbitrary sampling
times and locations, allowing us to simulate (for example) ancient
samples.

\begin{pythoncode}
demography = msprime.Demography.island_model(initial_size=[1, 1],
                                             migration_rate=1)
ts = msprime.sim_ancestry(
    samples=[
        msprime.SampleSet(1, population=0, time=0),
        msprime.SampleSet(1, population=0, time=0),
        msprime.SampleSet(1, population=0, time=0),
        msprime.SampleSet(1, population=1, time=0.75), # Ancient
        # sample in deme 1
    ],
    demography=demography,
    ploidy=1,
    random_seed=22)
tree = ts.first()
\end{pythoncode}

\begin{figure}[t]
\centering
\includegraphics[width=0.48\textwidth]{images/plot_9.pdf}
\caption{\label{fig-tree-ancient-samples} Example tree produced by simulation
with ancient samples.}
\end{figure}

The tree produced by this code chunk is shown in Figure~\ref{fig-tree-ancient-samples}.
All of the trees that we previously considered had leaf nodes at time
zero. In this case, the samples 0, 1 and 2 are taken at time 0 in
population 0, but node 3 is sampled at time 0.75 in population 1.

Note that sampled individuals and nodes are defined sequentially based
on the order in which they are provided to the \texttt{samples} parameter. Also, it is vital
to note that changing the ploidy parameter only affects the number of samples drawn from
the population, not the actual simulation; simulations will be performed on the
haploid coalescent scale by default. The ploidy of the simulation can be changed by the
\texttt{ploidy} parameter in the \texttt{sim\_ancestry} function.


\subsection{Recombination}\label{recombination}

One of the key innovations of \msprime\ is that it makes simulation of the
full coalescent with recombination possible at whole-chromosome scale.
Adding recombination to a simulation is simple, requiring very minor
changes to the methods given above.

\begin{pythoncode}
ts = msprime.sim_ancestry(10, population_size=1e4, sequence_length=1e5, recombination_rate=1e-8, random_seed=3)
print(ts.num_trees)
>>> 135
\end{pythoncode}

    In this case, we provide two extra parameters: \texttt{length}, which
defines the length of the genomic region to be simulated, and
\texttt{recombination\_rate}, which defines the rate of recombination
per unit of sequence length, per generation. It is often useful to
think of both sequence lengths and recombination rates as defined in units of base-pairs. (Note, however, that these are continuous values, so this
correspondence should not be taken too literally. Note also that because \msprime\ assumes an infinite sites mutation model
the \texttt{length} parameter is not connected to the number
of mutational \emph{sites}. Thus any number of mutations can occur on a
given sequence length, depending on the mutation rate specified.)
For this example, we
defined a sequence length of 100kb, and a recombination rate of
\(10^{-8}\) per base per generation. The result of this particular simulation is a
\emph{tree sequence} that contains 82 distinct trees. Other replicate
simulations with different random seeds will usually result in different
numbers of trees.

Up to this point we have focused on simulations that returned a single
tree representing the genealogy of a sample. The inclusion of
recombination, however, means that there may be more than one tree
relating our samples. The \texttt{TreeSequence} object returned by
\msprime\ is a very concise and efficient representation of these highly
correlated trees. To process the trees, we simply consider
them one at a time, using the \texttt{trees()} iterator.

\begin{pythoncode}
tmrca = np.zeros(ts.num_trees)
breakpoints = np.zeros(ts.num_trees)
for tree in ts.trees():
    tmrca[tree.index] = tree.time(tree.root)
    breakpoints[tree.index] = tree.interval[0]
plt.ylabel("T_mrca (Generations)")
plt.xlabel("Position (kb)")
plt.plot(breakpoints / 1000, tmrca, "o");
\end{pythoncode}

\begin{figure}
\begin{center}
\includegraphics[width=\textwidth]{images/plot_10.pdf}
\end{center}
\caption{\label{fig:tree_tmrcas}Time to the MRCA of
a sample across a 100kb region.}
\end{figure}

This code generates the plot in Figure~\ref{fig:tree_tmrcas} showing the time of the MRCA of the sample for each tree across the
sequence. We find the \(T_{MRCA}\) as before, and plot this against the
left coordinate of the genomic interval that each tree covers. A full description of
\emph{tree sequences} and the methods for working with them is beyond the scope of this chapter (but see the online documentation for more details).

It is also possible to simulate data with recombination rates varying
across the genome (for example, in recombination hotspots). To do this, we
first create a \texttt{RecombinationMap} instance that describes the
properties of the recombination landscape that we wish to simulate. We
then supply this object to \texttt{simulate} using the
\texttt{recombination\_map} argument. In the following example, we
simulate 100 samples using the human chromosome 22 recombination map
from the HapMap project~\citep{international2003international}.
Figure~\ref{fig:variable_recombination} shows the
recombination rate and the locations of breakpoints
from the simulation, and the density of breakpoints closely follows the
recombination rate, as expected.

\begin{pythoncode}
# Read in the recombination map and run the simulation.
infile = "genetic_map_GRCh37_chr22.txt"
recomb_map = msprime.RateMap.read_hapmap(infile)
ts = msprime.sim_ancestry(
    samples=100,
    population_size=10**4,
    recombination_rate=recomb_map,
    ploidy=1,
    random_seed=1)
\end{pythoncode}

\begin{figure}
\begin{center}
\includegraphics[width=\textwidth]{images/plot_11.pdf}
\end{center}
\caption{\label{fig:variable_recombination} The HapMap
genetic map for chromosome 22 (blue) matches the density of breakpoints for a simulated chromosome (green) well.}
\end{figure}

Although coordinates are specified in floating point values, \msprime\
uses a discrete loci model when performing simulations. By default, the
number of loci is very large (\(\sim 2^{32}\)), and the locations of
breakpoints are translated back into the coordinate system defined by
the recombination map. However, the number of loci is configurable and
it is possible to simulate a specific number of discrete
loci.

\begin{pythoncode}
recomb_map = msprime.RateMap.uniform(sequence_length=10, rate=1)
ts = msprime.sim_ancestry(2, recombination_rate=recomb_map)
print(list(ts.breakpoints()))
>>> [0, 1.0, 2.0, 3.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]
\end{pythoncode}

    Here we simulate the history of two samples in a system with 10 loci, each of
length 1 with recombination rate of 1 between adjacent loci per
generation. In the output, we see that the breakpoints between trees now
occur exactly at the integer boundaries between these loci. This shows that
we can also simulate models of recombination with discrete loci models
in \msprime, as well as the more standard continuous genome.

\subsubsection{Gene conversion}\label{gene-conversion}

Beside simulating recombination, \msprime\ also supports gene conversion events.To simulate gene conversion,
two parameters are required: the gene conversion rate and the tract length distribution. By default, tract lengths are drawn
from a genometric distribution with a mean of 1.

Gene conversion can be simulated independently, or it can be simulated alongside recombination, provided that both rates are constants.
The following example shows a simulation with gene conversion and recombination.

\begin{pythoncode}
ts = msprime.sim_ancestry(
    3, gene_conversion_rate=0.02, gene_conversion_tract_length=1,
    sequence_length=10, random_seed=3)
\end{pythoncode}

\begin{figure}
\begin{center}
\includegraphics[width=\textwidth]{images/gene_conversion.pdf}
\end{center}
\caption{\label{fig:gene_conversion} An example of the effect of gene conversion on simulations.}
\end{figure}

In this example, as shown in Figure~\ref{fig:gene_conversion}, we see the gene conversion-specific effect; trees on either side of the event are identical.

\subsection{Ancestry Models}\label{ancestry-models}

By default, \msprime\ simulates the coalescent process based on the Hudson model~\citep{hudson1983properties}, referred to as the
\emph{StandardCoalescent model}. However, \msprime\ is able to simulate the coalescent process under other models, such as
\emph{SMC models}~\citep{mcvean2005approximating} and the \emph{DiscreteTimeWrightFisher model (DTWF)}~\citep{nelson_accounting_2020}(for a full list of
supported models please refer to the \msprime\ documentation).

The model used for the simulation is specified using the \texttt{model} parameter
in the \texttt{sim\_ancestry} function. Moreover, \msprime\ can combine different models; for example, the DTWF model can be used to simulate the more recent
past, while the faster standard model can be used to simulate the more distant past.

\begin{pythoncode}
ts = msprime.sim_ancestry(
    2,
    population_size=1000,
    model=[
        msprime.DiscreteTimeWrightFisher(duration=500),
        msprime.StandardCoalescent(),
    ],
    random_seed=4
)

\end{pythoncode}

In this code block, for example, we simulate the coalescent process for two samples under the \emph{DTWF} model for the first 500 generations,
and then switch to the \emph{StandardCoalescent} model for the remaining generations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Processing results}\label{processing-results}

In the previous section we showed how to run simulations in \msprime, and
how to construct population models and demographic histories. In this
section we show how to process the results of simulations. This is not a
comprehensive review of the capabilities of the \msprime\ Python API, but
concentrates on some useful examples.
\msprime\ is specifically designed to enable very large simulations, and
the processing methods we demonstrate below are all very efficient. To
illustrate this, we consider a simulation of 200,000 samples of 10 megabases
from a simple two-population model with human-like parameters:

\begin{pythoncode}
demography = msprime.Demography.isolated_model([2*(10**4)]*2)
demography.add_mass_migration(time=50000, source=1, dest=0, proportion=1.0)

ts = msprime.sim_ancestry(
    samples={0: 10**5, 1: 10**5},
    demography=demography, recombination_rate=1e-8,
    sequence_length=10*10**6, random_seed=3,
    ploidy=1)

ts = msprime.sim_mutations(ts, rate=1e-8, random_seed=7, discrete_genome=False)
print((ts.num_trees, ts.num_sites))

>>> (93844, 102270)
\end{pythoncode}

This simulation required about 20 seconds to complete.


\subsection{Computing MRCAs}\label{computing-mrcas}

We are often interested in finding the most recent common ancestor (MRCA)
of a pair (or many pairs) of samples. For example, identity-by-descent
(IBD) tracts are defined as contiguous stretches of genome in which the
MRCA for a pair of samples is the same. Computing IBD segments for a
pair of samples is very straightforward:

\begin{pythoncode}
def ibd_segments(ts, a, b):
    trees_iter = ts.trees()
    tree = next(trees_iter)
    last_mrca = tree.mrca(a, b)
    last_left = 0
    segment_lengths = []
    for tree in trees_iter:
        mrca = tree.mrca(a, b)
        if mrca != last_mrca:
            left = tree.interval[0]
            segment_lengths.append(left - last_left)
            last_mrca = mrca
            last_left = left
    segment_lengths.append(ts.sequence_length - last_left)
    return np.array(segment_lengths) / ts.sequence_length

sns.histplot(ibd_segments(ts, 0, 1), label="Within population", kde=True,
    stat="density")
sns.histplot(ibd_segments(ts, 0, 10**5), label="Between populations", kde=True,
    stat="density")
plt.xlim(-0.0001, 0.003)
plt.legend()
plt.ylabel("Count")
plt.xlabel("Fraction of genome length");
\end{pythoncode}

\begin{figure}
\begin{center}
\includegraphics[width=\textwidth]{images/plot_12.pdf}
\end{center}
\caption{\label{fig:ibd_segments} The distribution of the length of IBD
segments for a pair of samples taken from the same or different populations.}
\end{figure}

In this example we create a function \texttt{ibd\_segments} that returns
a NumPy array of the lengths of IBD segments for a given pair of
samples, \texttt{a} and \texttt{b}. It works simply by computing the
MRCA for the samples at the left hand side of the sequence and then,
moving rightwards, records a segment each time the MRCA changes. We then
plot the distribution of tract lengths for samples 0 and 1 (which are
both in population 0), and also the tract lengths for a pair of
samples from different populations. The results are shown in
Figure~\ref{fig:ibd_segments}. As we might expect, the tract
lengths are shorter for the between population pair.

Of course, we would need to sample many such pairs of samples or longer sequences to get a reasonable approximation of the real distribution of block lengths.
Because the main cost of this function is the iteration over all the
trees in the sequence, it would be more efficient to keep track of the MRCAs
for different pairs in a single iteration rather than repeatedly
call the above \texttt{ibd\_segments} function.

\subsection{Sample counts}\label{sample-counts}

The \msprime\ API provides an extremely efficient way to count the number of samples that are beneath a particular node in a tree. This can be used,
for example, to compute allele frequencies efficiently and is the basis
for many of the fast algorithms in the API. As a simple illustration of
this technique, consider the following code to compute the number of
sites with derived allele frequency less than 1\%:

\begin{pythoncode}
N = ts.num_samples
threshold = 0.01
num_rare_derived = 0
for tree in ts.trees():
    for site in tree.sites():
        assert len(site.mutations) == 1
        mutation = site.mutations[0]
        if tree.num_samples(mutation.node) / N < threshold:
            num_rare_derived += 1
print((num_rare_derived, num_rare_derived / ts.num_sites))

>>> (65292, 0.635241236391232)
\end{pythoncode}

    In this example we iterate over all the trees in the tree sequence, and
then iterate over all the sites in each tree. We find the frequency
of the derived allele at each site using the \texttt{num\_samples}
method, which returns the number of samples subtending a given
node. The underlying implementation ensures that this operation requires
constant time, and so it is \emph{very} efficient. We see that such rare alleles are common.
(We reiterate that \msprime\ currently
generates mutations under the infinitely many sites model so that each mutation occurs at a
unique site. Future versions of \msprime\ or other software packages may produce
tree sequences with back or recurrent mutations, where
this simple approach will not work.
To emphasise this point and to ensure that the above code chunk is not
accidentally applied in such sitations we have included an
\texttt{assert} statement. We use asserts in a similar way in later
code chunks.)

A powerful feature of this sample-counting approach is that we can
perform the same operation over an arbitrary subset of the samples. For
example, suppose we wished to count the number of sites that are private
to a specific population:

\begin{pythoncode}
def num_private_sites(pop_id):
    pop_samples = ts.samples(pop_id)
    num_private = 0
    for tree in ts.trees(tracked_samples=pop_samples):
        for site in tree.sites():
            assert len(site.mutations) == 1
            mutation = site.mutations[0]
            total = tree.num_samples(mutation.node)
            within_pop = tree.num_tracked_samples(mutation.node)
            if total == within_pop:
                num_private += 1
    return num_private

private_0 = num_private_sites(0)
private_1 = num_private_sites(1)
print((ts.num_sites, private_0 + private_1, private_0, private_1))

>>> (102783, 102117, 50850, 51267)
\end{pythoncode}

    This example is very similar, except we provide an extra argument to
\texttt{ts.trees}. The \texttt{tracked\_samples} argument specifies a list of samples to be tracked, which can be
any arbitrary subset of the samples in the simulation. Here we indicate
that we are interested in tracking the set of samples within the
population in question. Again, we iterate over all trees and over all
sites within trees. Then, for each infinite sites mutation we
compute two frequencies: the overall number of samples that inherit from
the mutation's node, and the number of tracked samples \emph{within the focal
population} that inherit from this node. If the total count is
equal to the within-population count, we know that this mutation is private to the population.

\subsection{Obtaining subsets}\label{obtaining-subsets}

In some situations it is useful to analyse data for different subsets of
the samples separately. This is possible using the \texttt{simplify}
method:

\begin{pythoncode}
samples = [1, 3, 5, 7]
ts_subset = ts.simplify(samples)
print((
    ts_subset.num_sites, ts_subset.num_trees,
    ts.num_sites, ts.num_trees))
>>> (11925, 5323, 102783, 93598)
\end{pythoncode}

Here we extract the tree sequence representing the history of a tiny
subset of the original samples, with IDs 1, 3, 5 and 7. The subset tree
sequence contains all the genealogical information relevant to the
subsamples, but no more. Concretely, both coalescences that are not ancestral to the
subsample and coalescences that predate
the MRCA of the subsample are excluded. Thus, the number of distinct trees is greatly
reduced. By default, we also remove any sites that have no mutations
within these subtrees (i.e., those that are fixed for the ancestral
state). These can be retained by using the
\texttt{filter\_zero\_mutation\_sites=False} argument.

Node IDs in the simplified tree sequence are not the same as in the
original. The \texttt{map\_nodes} argument allows us to obtain the
mapping from IDs in the original tree sequence to their equivalant nodes
in the new tree sequence.

\begin{pythoncode}
ts_subset, node_map = ts.simplify(samples, map_nodes=True)
tree = ts_subset.first()
node_labels = {
    node_map[j]: "{}({})".format(node_map[j], str(j))
    for j in range(ts.num_nodes)}
SVG(tree.draw(node_labels=node_labels, width=400))
\end{pythoncode}

\begin{figure}[t]
\centering
\includegraphics[width=0.48\textwidth]{images/plot_13.pdf}
\caption{\label{fig-tree-subset} Tree of a subset of the samples in a large
simulation. Node IDs in the subset and full tree sequences are shown.}
\end{figure}

The result of running this code chunk is show in Figure~\ref{fig-tree-subset}.
Here we draw the first tree in the subset tree sequence, showing the new
node IDs along with the IDs from the original tree sequence in
parentheses. The number of nodes is greatly reduced from the original.

\subsection{Processing variants}\label{processing-variants}

While it is nearly always more efficient to work with mutations in terms
of their context within the trees, it is sometimes more convenient to
work with the allelic states of the samples. This information is
obtained in msprime using the \texttt{variants()} iterator, which
returns a \texttt{Variant} object for each site in the tree sequence. A
\texttt{Variant} consists of: (a) a reference to the \texttt{Site} in question;
(b) the \texttt{alleles} at this site (the strings representing the
actual states); and (c) the \texttt{genotypes} representing the observed
state for each sample. The \texttt{genotypes} are encoded in a NumPy
array, such that \texttt{variant.alleles{[}variant.genotypes{[}j{]}{]}}
gives the allelic state for sample ID \texttt{j}. The values in the
\texttt{genotypes} array are therefore indexes into the \texttt{alleles}
list. The ancestral state at a given site is guaranteed to be the first
element in the \texttt{alleles} list, but no other assumptions about
ordering of the alleles list should be made.

For biallelic sites, working with genotypes is straightforward as the
genotypes array can only contain 0 and 1 values, which correspond to
the ancestral and derived states, respectively. The \texttt{genotypes}
values are returned as a NumPy array, and so the full NumPy library is
available for efficient processing. As an example, we show here how to
count the number of sites at which the derived allele is at frequency
less than 10\%. Using the genotypes in this way is convenient, as
complex patterns of back and recurrent mutations can be handled without
difficulty.

\begin{pythoncode}
%%time
threshold = 0.1
num_rare = 0
for variant in ts.variants():
    # Will work for any biallelic sites; back/recurrent mutations OK
    assert len(variant.alleles) == 2
    if np.sum(variant.genotypes) / ts.num_samples < threshold:
        num_rare += 1
print(num_rare)
>>> 83757
CPU times: user 1min 30s, sys: 4 ms, total: 1min 30s
\end{pythoncode}

This code is straightforward, as we simply iterate over all variants and
count the number of 1 values in the genotypes array. Using the \texttt{np.sum}
function, this operation is efficient. Generating all the genotypes for
200,000 samples at 100,000 sites, however,
is an expensive operation and the overall calculation takes about 1.5 minutes
to complete.

In the case of infinite sites mutations, we can recast this operation
to use the efficient sample counting methods describe in
Section~\ref{sample-counts}. This approach is far more
efficient, requiring less than 2 seconds to compute the same value.
\begin{pythoncode}
%%time
num_rare = 0
for tree in ts.trees():
    for site in tree.sites():
        # Only works for infinite sites mutations.
        assert len(site.mutations) == 1
        mutation = site.mutations[0]
        if tree.num_samples(mutation.node) / ts.num_samples < threshold:
            num_rare += 1
print(num_rare)
>>> 83757
CPU times: user 1.75 s, sys: 36 ms, total: 1.79 s
\end{pythoncode}

\subsection{Incremental calculations}\label{incremental-calculations}

A powerful property of the tree sequence representation is that we can
efficiently find the differences between adjacent trees. This is very
useful when we have some value that we wish to compute that changes in a
simple way between trees. The \texttt{edge\_diffs} iterator provides us
with the information that we need to perform such incremental
calculations. Here we use it to keep a running track of the total branch
length of our trees, without needing to perform a full traversal each
time.

\begin{pythoncode}
def get_total_branch_length(ts):
    current = 0
    total_branch_length = np.zeros(ts.num_trees)
    for j, (_, edges_out, edges_in) in enumerate(ts.edge_diffs()):
        for e in edges_out:
            current -= ts.node(e.parent).time - ts.node(e.child).time
        for e in edges_in:
            current += ts.node(e.parent).time - ts.node(e.child).time
        total_branch_length[j] = current
    return total_branch_length
\end{pythoncode}

    This function returns the total branch length value for each tree in the
sequence as a NumPy array. It works by keeping track of the total branch
length as we proceed from left to right, and storing this value in the
output array for each tree. The \texttt{edge\_diffs} method returns a
list of the edges that are removed for each tree transition
(\texttt{edges\_out}) and a list of edges that are inserted
(\texttt{edges\_in}). Computing the current value for the total branch
length is then simply a case of subtracting the branch lengths for all
outgoing edges and adding the branch lengths for all incoming edges.
This is extremely efficient because, after the first tree has been
constructed there is at most four incoming and outgoing edges~\citep{kelleher2016efficient}. Thus,
each tree transition costs \emph{constant time}.

\begin{pythoncode}
%%time
tbl = get_total_branch_length(ts)

CPU times: user 7.67 s, sys: 64 ms, total: 7.74 s
\end{pythoncode}

In contrast, if we compute the total branch length by performing a
full traversal for each tree, each tree transition is very costly
when we have a large sample size. In this example, computing the array of branch lengths
using the incremental approach given here took 8 seconds. Computing the
same array using the \texttt{tree.total\_branch\_length} for each tree
in a straightforward way still had not completed after \emph{twenty
minutes}. (This is because \msprime\ currently implements this operation
by a full traversal in Python; in future this may change to using the
algorithm given here.) Full tree traversals of large trees are
expensive, and great gains can be made if calculations can be expressed
in an incremental manner using \texttt{edge\_diffs}.


\subsection{Exporting variant data}\label{exporting-variant-data}

If the \msprime\ API doesn't provide methods to easily calculate the
statistics you are interested in, it's straightforward to export the
variant data into other libraries using the \texttt{genotype\_matrix()}
or \texttt{variants()} methods. We recommend the excellent
\texttt{scikit-allel}~\citep{miles2017scikit} and
\texttt{pylibseq} [\url{https://pypi.python.org/pypi/pylibseq}],
libraries (\texttt{pylibseq} is a Python interface to
\texttt{libsequence}~\citep{thornton2003libsequence}). If you wish to export data to
external programs, VCF may be best option, which is supported using the
\texttt{write\_vcf} method. The \texttt{simplify} method is useful here
if you wish to export data from a subset of the simulated samples.

However, it is worth noting that for large sample sizes, exporting
genotype data may require a great deal of memory and take some time. One
of the advantages of the \msprime\ API is that we do not need to
explicitly generate genotypes in order to compute many
statistics of interest.

\section{Validating analytic predictions}\label{validating-analytical-predictions}

In this section we show some examples of validating simple analytic
predictions from coalescent theory using simulations. The number of
segregating sites is the total number of mutations that occurred in the
history of the sample (assuming the infinite sites mutation model).
Since mutations happen as a Poisson process along the branches of the
tree, what we are really interested in is the distribution of the total
branch length of the tree. The results in this section are well known
classical results from coalescent theory; this section is intended as a
demonstration of how to proceed when comparing analytic results to
simulations. We show some idiomatic examples for integrating with
the state-of-the-art data analysis packages such
as Pandas~\citep{mckinney2010data} and Seaborn~\citep{michael_waskom_2017_883859}.
All analytic predictions are taken from \cite{wakely2008coalescent}.

\subsection{Total branch length and segregating sites}
The first properties we are interested in are the mean and the
variance of the total branch length of coalescent trees. (Note that, as
before, we set \(N_e=1/2\) to convert between \msprime's diploid time
scaling to the haploid time scaling of these analytic results.)

\begin{pythoncode}
ns = np.array([5, 10, 15, 20, 25, 30])
num_reps = 10000
n_col = np.zeros(ns.shape[0] * num_reps)
T_total_col = np.zeros(ns.shape[0] * num_reps)
row = 0
for n in ns:
    for ts in msprime.sim_ancestry(n, population_size=1, num_replicates=num_reps, ploidy=1):

        tree = ts.first()
        n_col[row] = n
        T_total_col[row] = tree.total_branch_length
        row += 1
df = pd.DataFrame({"n": n_col, "T_total": T_total_col})
\end{pythoncode}

    We first create an array of the six different \(n\) values that we wish to simulate, and then create arrays to hold the results of the
simulations. Because we are running 10,000 replicates for each sample
size, we allocate arrays to hold 60,000 values. This approach of storing
the data in arrays is convenient because it allows us to use Pandas
dataframes in an idiomatic fashion. We then iterate
over all of our sample sizes and run 10,000 replicates of each. For each
simulation, we simply store the sample size value and the total branch
length in a Pandas dataframe. This gives us access to many powerful data analysis tools (including the Seaborn library, which we use for visualisation here).

After we have created our simulation data, we define our analytic
predictions and plot the data.

\begin{pythoncode}
def T_total_mean(n):
    return 2 * np.sum(1 / np.arange(1, n))

def T_total_var(n):
    return 4 * np.sum(1 / np.arange(1, n)**2)

mean_T = np.array([T_total_mean(n) for n in ns])
stddev_T = np.sqrt(np.array([T_total_var(n) for n in ns]))
ax = sns.violinplot(
    x="n", y="T_total", data=df, color="grey", inner=None)
ax.plot(mean_T, "-");
ax.plot(mean_T - stddev_T, "--", color="black");
ax.plot(mean_T + stddev_T, "--", color="black");
group = df.groupby("n")
mean_sim = group.mean()
stddev_sim = np.sqrt(group.var())
x = np.arange(ns.shape[0])
ax.plot(x, mean_sim, "o")
line, = ax.plot(x, mean_sim - stddev_sim, "^")
ax.plot(x, mean_sim + stddev_sim, "^", color=line.get_color());
\end{pythoncode}

% \begin{figure}
% \begin{center}
%     \parbox{5cm}{
%     \includegraphics[width=5cm]{images/plot_14.pdf}
%     \begin{center}(A)\end{center}
%     }%
%     \qquad
%     \parbox{5cm}{
%     \includegraphics[width=5cm]{images/plot_15.pdf}
%     \begin{center}(B)\end{center}
%     }
%     \caption{Comparisons of the distribution of simulated total branch lengths
%         with analytic results. (A) The full distribution of simulated
%         values (violin plots) along with observed and predicted mean and
%         standard deviations for a range of sample sizes. (B) The full
%         simulated and predicted distribution of total branch lengths
%         for $n = 20$.}
%     \label{fig:segsites-norecomb}
% \end{center}
% \end{figure}

\begin{figure}[t]
\centering
\subfloat[][
The full distribution of simulated
values (violin plots) along with observed and predicted mean and
standard deviations for a range of sample sizes.
]{
\includegraphics[width=0.75\textwidth]{images/plot_14.pdf}
\label{fig-segsites-norecomb-a}}
\qquad\qquad
\subfloat[][
The full simulated and predicted distribution of total branch length for $n = 20$.
]{
\includegraphics[width=0.75\textwidth]{images/plot_15.pdf}
\label{fig-segsites-norecomb-b}}
\caption{\label{fig-segsites-norecomb}
Comparisons of the distribution of simulated total branch lengths
with analytic results.
}
\end{figure}

    The plot in Figure~\ref{fig-segsites-norecomb-a} shows the simulated
distribution of the total branch length
over replicate simulations (each violin is a distribution for a given
sample size). We also show our analytic prediction for the mean and
variance of each distribution (the dashed lines show +/- one standard
deviation from the mean). Also shown are the observed means and standard
deviations from the simulations, as green circles and red triangles,
respectively. We can see that the simulated values match our theoretical
predictions for mean and variance very well. We can also see, however,
that these one-dimensional summaries of the distribution capture some
essential properties but lose some important aspects of the
distribution.

    Ideally, we wish to capture the full distribution analytically. In the following code chunk we define the analytic
prediction for the total branch length distribution, and compare it with the simulated distribution for a sample of size 20. The results are shown in
Figure~\ref{fig-segsites-norecomb-b}. We can see an excellent agreement between
the smoothed kernel
density estimate produced by Seaborn and the theoretical prediction.

\begin{pythoncode}
def T_total_density(n, t):
    e_t2 = np.exp(-t / 2)
    return 0.5 * (n - 1) * e_t2 * (1 - e_t2)**(n - 2)

n = 20
T_total_20 = T_total_col[n_col == n]
ts = np.linspace(0, np.max(T_total_20), 25)
t_densities = np.array([T_total_density(n, t) for t in ts])
sns.histplot(T_total_20, kde=True,
    stat="density")
plt.plot(ts, t_densities, marker="o", label="Analytical")
plt.xlabel("T_total")
plt.legend();
\end{pythoncode}

Since we cannot directly observe branch lengths, we are usually more
interested in mutations when working with data. The mutation process is
intimately related to the distribution of branch lengths, since
mutations occur randomly along tree branches. One simple summary of the
mutational process is the total number of segregating sites, that is, the number of
sites at which we observe variation. We can obtain this very
easily from simulations simply by specifying a mutation rate parameter.
(Note again that we set \(N_e=1/2\) and our mutation rate
\(= \theta / 2\) in order to convert to \msprime's time scales.)

\begin{pythoncode}
def S_dist(n, theta, k):
    S = 0
    for i in range(2, n + 1):
        S += ((-1)**i * scipy.special.binom(n - 1, i - 1)
              * (i - 1) / (theta + i - 1)
              * (theta / (theta + i - 1))**k)
    return S

n = 20
theta = 5
num_replicates = 1000
simulation = np.zeros(num_replicates)
replicates = msprime.simulate(
    n, Ne=0.5, mutation_rate=theta / 2, num_replicates=num_replicates)
for j, ts in enumerate(replicates):
    simulation[j] = ts.num_sites  # number of seg. sites
ks = np.arange(np.max(simulation))
analytical = np.array([S_dist(n, theta, k) for k in ks])
sns.histplot(simulation, kde=True,
    stat="density")
plt.plot(ks, analytical, marker='o', label="Analytical")
plt.xlabel("Segregating sites")
plt.legend();
\end{pythoncode}

\begin{figure}[t]
\centering
\subfloat[][
    The distribution of the number
    of segregating sites for $n=20$, $\theta=5$ and no recombination
    over 1000 simulation replicates, along with analytic prediction.]{
\includegraphics[width=0.75\textwidth]{images/plot_16.pdf}
\label{fig-segsites-a}}
\qquad\qquad
\subfloat[][
    The mean and variance of the number of segregating sites
    over 10000 simulation replicates with $n=2$, $\theta=2$ and
    varying recombination rate, along with analytic predictions.]{
\includegraphics[width=0.75\textwidth]{images/plot_17.pdf}
\label{fig-segsites-b}}
\caption{\label{fig-segsites}
Simulations of the number of segregating sites, and
comparisons with analytic predictions.
}
\end{figure}

Here we take 1000 replicate simulations, store the number of infinite
sites mutations for each and plot this distribution in
Figure~\ref{fig-segsites-a}. Also plotted is the analytic prediction, which again provides an excellent fit.


\subsection{Recombination}

In the previous section we saw how to run simulations to generate trees
under the assumptions of the single-locus coalescent and compare these
with analytic predictions. This assumes that our data is not affected
by recombination, which is often unrealistic. Here we show how to
compute empirical distributions of equivalent quantities, and compare
these with classical results from the literature. Since analytic
results for many quantities are generally unknown for the case of recombination along a linear sequence, we limit ourselves to the pairwise samples.

\begin{pythoncode}
theta = 2
num_replicates = 10000
rhos = np.arange(1, 10)
N = rhos.shape[0] * num_replicates
rho_col = np.zeros(N)
s_col = np.zeros(N)
row = 0
for rho in rhos:
    replicates = msprime.sim_ancestry(1, num_replicates=num_replicates,
                                        recombination_rate=rho/2, population_size=0.5,
                                        discrete_genome=False, sequence_length=1
                                     )

    for ts in replicates:
        ts = msprime.sim_mutations(ts, rate=theta/2, discrete_genome=False)

        rho_col[row] = rho
        s_col[row] = ts.num_sites
        row += 1
df = pd.DataFrame({"rho": rho_col, "s": s_col})
\end{pythoncode}

In this code chunk we again run $10^4$ replicate simulations for a range
of input parameters, and store the results in a Pandas data frame. We
are interested in the effects of recombination rate in this example,
and so the parameter that we vary is the scaled recombination rate
$\rho$ (noting, again, that we set $N_e = 1/2$ and
\texttt{recombination\_rate} = $\rho / 2$ to convert to \msprime's
time scales).

\begin{pythoncode}
def pairwise_S_mean(theta):
    return theta

def f2(rho):
    return (rho + 18) / (rho**2 + 13 * rho + 18)

def pairwise_S_var(theta, rho):
    integral = scipy.integrate.quad(lambda x: (rho - x) * f2(x), 0, rho)
    return theta + 2 * theta**2 * integral[0] / rho**2

group = df.groupby("rho")
plt.plot(group.mean(), "o", label="simulated mean")
plt.plot(group.var(), "^", label="simulated variance")
plt.plot(
    rhos, [pairwise_S_mean(theta) for rho in rhos], "-",
    label="Analytical mean")
plt.plot(rhos, [pairwise_S_var(theta, rho) for rho in rhos], "--",
label="Analytical variance")
plt.xlabel("rho")
plt.legend();
\end{pythoncode}

After defining our analytic predictions for the mean and variance of the
number of segregating sites, we then plot the observed and predicted values
in Figure~\ref{fig-segsites-b}.
Comparing the simulated results to analytic predictions we see
excellent agreement. The mean number of segregating sites is not
affected by recombination, but recombination does substantially reduce
the variance.

\section{Example inference scheme}\label{sec:inference}

    The analytical challenges of deriving likelihood functions even under
highly idealized models of population structure and history have led to
the development of likelihood-free inference methods, in particular
Approximate Bayesian Computation (ABC)~\citep{Beaumont2002}.
ABC approximates the posterior distribution of model parameters by drawing from
simulations. Because of its flexibility ABC has become a standard
inference tool in statistical population genetics \citep[see][for a review]{csillery2010approximate}.
We will demonstrate how \msprime\ can be used to set up an ABC inference
by means of a simple toy example. We stress that this is meant as an
illustration rather than a inference tool for practical use. However,
given the flexibility of \msprime, it should be
relatively straightforward to implement more a realistic framework focused
on specific inference applications.

We assume that data for 200 loci or sequence blocks (these could be RAD
loci in practice) for a single diploid individual have been generated
from each of two populations. We would like to infer the amount of gene
flow between the two populations. For the sake of simplicity we will
assume the simplest possible model of population structure; that is, two
populations, of the same effective size exchanging migrants at a
constant rate of $m$ migrants per generation.

The function \texttt{run\_sims} simulates a dataset consisting of a
specified number of loci (\texttt{num\_loci}) given a migration rate
\(M\). We generate a single dataset of 50 loci assuming a migration rate
\(M=0.3\) migrants per generation, which we will use as a (pseudo)observed dataset in the ABC
implementation.

\begin{pythoncode}
nsamp = 2
theta = 2
true_m = 0.3
num_loci = 200

def run_sims(m, num_loci=1, theta=0):
    demography = msprime.Demography.island_model([1, 1], migration_rate=m)
    replicates = msprime.sim_ancestry({0: nsamp, 1:nsamp},
                                      demography=demography,
                                      num_replicates=num_loci, ploidy=1,
                                      discrete_genome=False, sequence_length=1)
    for ts in replicates:
        yield msprime.sim_mutations(ts, rate=theta, discrete_genome=False)

def get_joint_site_frequency_spectra(reps):
    data = np.zeros((num_loci, nsamp + 1, nsamp + 1))
    for rep_index, ts in enumerate(reps):
        data[rep_index] = ts.allele_frequency_spectrum([[0, 1], [2,3]], polarised=True)

    return data

truth = get_joint_site_frequency_spectra(
    run_sims(true_m, num_loci=num_loci, theta=2))
\end{pythoncode}

    The \texttt{run\_sims} function returns an iterator with the complete
tree sequence and mutational information of each locus. We use the
function \texttt{get\_joint\_site\_frequency\_spectra} to summarize the
polymorphism information as the joint site frequency spectrum (jSFS) of
each locus, i.e. the blockwise site frequency spectrum
or bSFS \cite[sensu][]{Lohse2016}.
Note that higher level population genetic summaries, e.g.\ pairwise
measures of divergence and diversity such as \(D_{XY}\) \citep{Nei1972} and
\(F_{ST}\)~\citep{wright1950genetical} or multi-population \(F\)
statistics~\citep{Durand2009,patterson2012ancient} which are often
used in ABC inference are just further (and lossy) summaries of the jSFS.

Since \msprime\ simulates rooted trees, the columns and rows
of the unfolded jSFS correspond to the frequency of derived mutations in
each population and the entries of the jSFS are simply mutation counts.
E.g.\ for the first locus we have:
\begin{pythoncode}
print(truth[0])

>>> [[ 0.  14.  0.]
     [ 0.  0.  0.]
     [ 8.  1.  0.]]
\end{pythoncode}

    One could base inference on the bSFS \citep{Lohse2016, Beeravolu2017}, but we will for the sake of simplicity use a simpler (and lossy)
summary of the data: the average jSFS across loci. For analyses based on
SNPs, it is convient to normalize the jSFS by the total number of
mutations:
\begin{pythoncode}
truth_mean = np.mean(truth, axis=0)
truth_mean /= np.sum(truth_mean)
print(truth_mean)

>>> [[0.         0.24496958 0.16471689]
     [0.20846982 0.05662143 0.06948994]
     [0.16752457 0.08820777 0.        ]]
\end{pythoncode}

    To illustrate a simple ABC inference, we will focus on a single
parameter of interest, the migration rate \(M\).
ABC measures the fit of data simulated under the prior to the observed
data via a vector of summary statistics. We will use the jSFS as a
summary statistic and approximate the jSFS for each \(M\) value as the
mean length of genealogical branches across 100 simulation replicates (\texttt{num\_reps}). Below we
draw 10,000 \(M\) values from the prior and use the functions
\texttt{run\_sims} and \texttt{approx\_jSFS} to approximate the jSFS for
 replicate. We assume an exponential distribution, a common choice of prior \citep{hey2004multilocus}.

\begin{pythoncode}
import tskit

num_reps = 100
num_prior_draws = 10000
prior_m = np.random.exponential(0.1, num_prior_draws)

def approx_jSFS(m):
    reps = run_sims(m, num_loci=num_reps)
    B = np.zeros((num_reps, nsamp + 1, nsamp + 1))
    for rep_index, ts in enumerate(reps):
        B[rep_index] = ts.allele_frequency_spectrum([[0,1],[2,3]], mode='branch', polarised=True, span_normalise=False)
    data = np.mean(B, axis=0)
    return data / np.sum(data)

with cf.ProcessPoolExecutor(max_workers=4) as executor:
    futures = [executor.submit(approx_jSFS, prior) for prior in prior_m]
    prior_jSFS = np.array([f.result() for f in cf.as_completed(futures)])

print(prior_jSFS[0])
\end{pythoncode}

Here we run 100 simulation replicates for each of the 10,000
$m$ values drawn from the prior, giving a total of 1 million individual simulations.
We use the \texttt{concurrent.futures} module to distribute these
computations over the available CPU cores.

Once this has completed, we compute the Euclidean distance between the estimated branch-jSFS for each
draw from the prior (\texttt{prior\_jSFS}) and the site-jSFS in the (pseudo)observed
data (\texttt{truth\_mean}), as both values should be similar~\citep{ralph_efficiently_2020}.:
\begin{pythoncode}
distances = np.zeros(num_prior_draws)
for j in range(num_prior_draws):
    distances[j] = np.sqrt(np.sum((prior_jSFS[j] - truth_mean)**2))
\end{pythoncode}

\begin{figure}[t]
\centering
\subfloat[][
Prior and posterior ABC distributions
and estimated 95\% approximate credible interval.
]{
\includegraphics[width=0.75\textwidth]{images/plot_18.pdf}
\label{fig-abc-a}}
\qquad\qquad
\subfloat[][
Mean and root-mean-square-error of migration rate estimates computed
from pseudo-observed data sets.]{
\includegraphics[width=0.75\textwidth]{images/plot_20.pdf}
\label{fig-abc-b}}
\caption{\label{fig-abc}ABC results.}
\end{figure}

% \begin{figure}
% \begin{center}
%     \parbox{5cm}{
%     \includegraphics[width=5cm]{images/plot_18.pdf}
%     \begin{center}(A)\end{center}
%     }%
%     \qquad
%     \parbox{5cm}{
%     \includegraphics[width=5cm]{images/plot_20.pdf}
%     \begin{center}(B)\end{center}
%     }
%     \caption{ABC results. (A)  Prior and posterior ABC distributions
%     and estimated 95\% approximate credible interval.
%     (B) Mean and root-mean-square-error of
%     migration rate estimates computed from pseudo-observed data sets.}
%     \label{fig:abc}
% \end{center}
% \end{figure}

    In its simplest form, ABC approximates the posterior by sampling from
the simulated data via an acceptance threshold. Here we approximate the
posterior distribution of \(m\) using the 5\% of simulation replicates
that most closely match the average jSFS of the observed data.
Figure~\ref{fig-abc-a} shows that the posterior
distribution (shown in green) is centred around \(m=0.25\).
\begin{pythoncode}
cutoff = np.percentile(distances, 5)
keep = np.where(distances < cutoff)
post_m = prior_m[keep]
mean_m = np.mean(post_m)
ci_m = np.percentile(post_m, 2.5), np.percentile(post_m, 95.75)
sns.histplot(prior_m, label="Prior", kde=True,
    stat="density")
sns.histplot(post_m, label="Posterior", kde=True,
    stat="density")
# Plotting code omitted.
\end{pythoncode}

The mean and the 95\% approximate posterior credible interval for \(m\)
are:
\begin{pythoncode}
print([mean_m, ci_m])

>>> [np.float64(0.2706689107323255), (np.float64(0.1680558635307605), np.float64(0.40359485279569585))]
\end{pythoncode}


Although the true value of \(m=0.3\) is contained within the 95 \% credible interval, the posterior distribution is clearly downwardly biased. This bias is in fact expected given that our prior is also strongly biased towards low \(m\). We can check the effect the acceptance threshold on the inference and get a sense of the expected information about \(m\) using a cross-validation procedure: we repeat the inference on pseudo-observed data sets (PODS) simulated under a known truth. Since we can re-use the same set of replicates simulated under the prior for inference, such cross-validation is computationally efficient.

Figure~\ref{fig-abc-b} shows the mean and the root mean square error (RMSE) of \(m\) estimates (across 100 PODS) against the acceptance threshold and confirms that both the downward bias in \(m\) estimates and the associated RMSE increase with larger acceptance tresholds. While this toy example illustrates the principle of ABC inference, sampling only a small fraction of simulations generated under the prior is clearly computationally inefficient and more efficient sampling strategies for ABC inference have been developed \citep{Beaumont2002}. In practice, we are generally interested in fitting parameter-rich models and it would be straightforward to implement ABC inference for complex model of population structure and demography in \msprime.

\section{Discussion}
\label{sec:discussion}
In this chapter we have focused on the usage of \msprime\ as a coalescent
simulator, and illustrated its flexibility through concrete examples.
While many examples discuss how to create and run the simulations themselves, others are concerned with how we analyse the \emph{output} of
these simulations. We have shown particularly in Section~\ref{processing-results}
that these methods can be very efficient, allowing us to easily analyse
chromosome scale data for hundreds of thousands of samples.
The data structures and APIs used in \msprime\ are
currently being developed to increase their generality
and applicability. Recent work~\citep{kelleher2018efficient,haller2018tree} has shown
that forward-time simulations can also benefit from these methods. By
recording all genealogical information for the simulated population
in the form of a succinct tree sequence,
we avoid the need to generate and carry forward neutral mutations;
by definition, they do not affect the genealogies, and can therefore
be placed on them afterwards. Not only does
this provide us with much more complete information about the forward-time
simulation, it also leads to substantially faster running times
(up to 50X faster, in the simulations performed). Through the use
of a well documented interchange API and thoroughly specified
data formats, forward-time simulators can output data that
is compatible with the \msprime\ API, and precisely the same
techniques described here can be used to analyse the results.
Thus, code written to analyse coalescent simulations can equally
be applied to analyse forwards simulations.

There is currently a great deal of activity from a growing community
around \msprime. We plan to separate the tree sequence processing code
from the simulator and create a library, provisionally known
as \texttt{tskit}. This standalone library (C and Python interfaces
are planned) will greatly facilitate integration with
forwards-time simulators, allowing them to easily offload
tree sequence processing to \texttt{tskit}. Algorithms for efficiently
calculating statistics using the incremental techniques outlined
in Section~\ref{incremental-calculations} are in development, and
promise to be significantly more efficient that the state-of-the-art.
Also in development are methods to estimate the tree sequence data
structure from real data, which would allow us to use these
efficient algorithms on observed as well as simulated data. New
features are being added to the \msprime\ simulator also, with
support for a discrete time Wright-Fisher model and a family of
multiple-merger coalescent models in development. We hope that
in the coming years a diverse ecosystem of tools and applications
using these APIs and data structures will emerge.

\section*{Acknowledgments}

We would like to thank Simon Aeschbacher for comments on the ABC inference example,
and to thank Yan Wong, Joseph Marcus and Julien Dutheil for
detailed and insightful feedback.
JK is supported by Wellcome Trust grant 100956/Z/13/Z to Gil McVean.
KL is supported by an Independent Research fellowship from the Natural Environment Research Council (NE/L011522/1).

\section*{Online resources}

\begin{tabular}{ll}
Jupyter notebook & \url{https://github.com/jeromekelleher/spg-chapter} \\
Documentation & \url{https://tskit.dev/msprime/docs/} \\
GitHub & \url{https://github.com/tskit-dev/msprime} \\
Tskit & \url{https://tskit.dev/} \\
Tskit documentation & \url{https://tskit.dev/tskit/docs/stable/} \\
Tskit tutorials & \url{https://tskit.dev/tutorials} \\
\end{tabular}

\bibliography{references}

\end{document}
